{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#Vers. 1.0.0\n",
    "print(tf.__version__)\n",
    "import sys\n",
    "#Should be above 3.5\n",
    "#print (sys.version)     \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import color\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "import re\n",
    "from Helpers import get_files, load_image, separate_imgs, get_next_batch_from_disk_RGB, get_next_batch_from_disk_RGB_Nocrop, get_next_batch_from_disk_HSV, get_next_batch_from_disk_Nocrop_HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18617"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_list = get_files(\"../Data/Old/*\", '*.jpg')\n",
    "len(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1, seed=seed, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(scope, x, kernel_size, stride=1):\n",
    "    W = weight_variable(kernel_size, \"conv_W_\" + scope)\n",
    "    b = bias_variable(kernel_size[3:], \"conv_b_\" + scope)\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    return  tf.nn.relu(conv +  b)\n",
    "\n",
    "#From https://github.com/shekkizh/Colorization.tensorflow/blob/master/TensorflowUtils.py\n",
    "def conv2d_transpose_strided(scope, x, kernel_size, stride=2, output_shape=None):\n",
    "    W = weight_variable(kernel_size, \"deconv_W_\" + scope)\n",
    "    b = bias_variable(kernel_size[3:], \"deconv_b_\" + scope)\n",
    "    \n",
    "    if output_shape is None:\n",
    "        output_shape = x.get_shape().as_list()\n",
    "        output_shape[1] *= 2\n",
    "        output_shape[2] *= 2\n",
    "        output_shape[3] = W.get_shape().as_list()[2]\n",
    "        \n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "def batch_norm(scope, x, train=True, reuse=False):\n",
    "    return tf.contrib.layers.batch_norm(x, center=True, scale=True, updates_collections=None, is_training=train, trainable=True, scope=scope)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network_colorization_nilboyarch_HSV(x):\n",
    "    \n",
    "    #conv1\n",
    "    conv_num = 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), x, [3, 3, 1, 64], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 64, 64], stride=2)\n",
    "    conv_num += 1\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "\n",
    "    #self.nilboy = temp_conv\n",
    "\n",
    "    temp_conv = batch_norm('bn_1', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    #conv2\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 64, 128], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 128, 128], stride=2)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = batch_norm('bn_2', temp_conv,train=is_training)\n",
    "    \n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    #conv3\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 128, 256], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 256, 256], stride=1)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 256, 256], stride=2)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = batch_norm('bn_3', temp_conv, train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    \n",
    "    #conv4\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 256, 512], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    \n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = batch_norm('bn_4', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "\n",
    "    #conv5\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = batch_norm('bn_5', temp_conv,train=is_training)\n",
    "    \n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    #conv6\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = batch_norm('bn_6', temp_conv,train=is_training) \n",
    "    \n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    #conv7\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = batch_norm('bn_7', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    \n",
    "    #Dropout layer for OF\n",
    "    temp_conv = tf.nn.dropout(temp_conv, keep_prob)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    \n",
    "    #conv8\n",
    "    temp_conv = conv2d_transpose_strided('conv' + str(conv_num), temp_conv, [4, 4, 256, 512], stride=2)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 256, 256], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 256, 256], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = batch_norm('bn_8', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "\n",
    "    \n",
    "    #conv9\n",
    "    temp_conv = conv2d_transpose_strided('conv' + str(conv_num), temp_conv, [3, 3, 128, 256], stride=2)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 128, 128], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 128, 128], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = batch_norm('bn_9', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    #conv10\n",
    "    temp_conv = conv2d_transpose_strided('conv' + str(conv_num), temp_conv, [3, 3, 64, 128], stride=2)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 64, 64], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 64, 64], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = batch_norm('bn_10', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    W_last = weight_variable([3, 3, 64, 2], 'conv_W_last')\n",
    "    b_last = bias_variable([2], 'conv_b_last')\n",
    "    last_cnn = tf.nn.l2_normalize(tf.nn.conv2d(temp_conv, W_last, strides=[1, 1, 1, 1], padding='SAME') , dim=2 , epsilon=1e-12)\n",
    "    print(last_cnn.get_shape())\n",
    "    \n",
    "    \n",
    "    _lambda = 0.05;\n",
    "    l1_regularizer = tf.contrib.layers.l1_regularizer(scale=_lambda, scope=None)\n",
    "    regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "    \n",
    "    \n",
    "    #Loss computation\n",
    "    gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(last_cnn - y)) + regularization_penalty\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(gen_loss_mse)\n",
    "    \n",
    "    #pred image\n",
    "    tf.add_to_collection('optimizer', optimizer)  \n",
    "    tf.add_to_collection('loss', gen_loss_mse) \n",
    "    tf.add_to_collection('color_image', last_cnn)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Training\n",
    "    for itr in range(hm_epochs):\n",
    "        #image, color_images = get_next_batch(train_features, train_labels)\n",
    "        image, color_images = get_next_batch_from_disk_HSV(images_list=images_list, batch_size=batch_size, crop_size=224)\n",
    "        #print(image.shape)\n",
    "        feed_dict = {x: image, y: color_images, keep_prob: dropout_keep_prob, is_training : True}\n",
    "        sess.run(optimizer, feed_dict=feed_dict)\n",
    "        \n",
    "        if itr % 20 == 0:\n",
    "            mse = sess.run(gen_loss_mse, feed_dict=feed_dict)\n",
    "            sess.run(optimizer, feed_dict=feed_dict)\n",
    "            print(\"Step: %d, MSE: %g\" % (itr, mse))\n",
    "     \n",
    "    saver.save(sess, model_path)\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 112, 112, 64)\n",
      "(15, 112, 112, 64)\n",
      "(15, 56, 56, 128)\n",
      "(15, 28, 28, 256)\n",
      "(15, 28, 28, 512)\n",
      "(15, 28, 28, 512)\n",
      "(15, 28, 28, 512)\n",
      "(15, 28, 28, 512)\n",
      "(15, 28, 28, 512)\n",
      "(15, 56, 56, 256)\n",
      "(15, 112, 112, 128)\n",
      "(15, 224, 224, 64)\n",
      "(15, 224, 224, 2)\n",
      "Step: 0, MSE: 435436\n",
      "Step: 20, MSE: 366641\n",
      "Step: 40, MSE: 390053\n",
      "Step: 60, MSE: 387764\n"
     ]
    }
   ],
   "source": [
    "#Global constants\n",
    "seed = 56\n",
    "\n",
    "#cycles of feed forward + backprop on all K-folded samples\n",
    "hm_epochs = 61\n",
    "dropout_keep_prob = 0.5\n",
    "\n",
    "model_path = \"./ghibli_HSV_norm/model.ckpt\"\n",
    "save_dir = './ghibli_HSV_norm/'\n",
    "\n",
    "batch_size = 15\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, 224, 224, 1], name = 'x')\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, 224, 224, 2], name='y')\n",
    "keep_prob = tf.placeholder(tf.float32, name = 'keep_prob')\n",
    "is_training = tf.placeholder(tf.bool, name = 'is_training');\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "train_neural_network_colorization_nilboyarch_HSV(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v, hs = get_next_batch_from_disk_HSV2(images_list=images_list, batch_size=3, crop_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_neural_network_colorization_sig(x):\n",
    "    \n",
    "    strides1 = [1, 1, 1, 1]\n",
    "    strides2 = [1, 2, 2, 1]\n",
    "    \n",
    "    # first convolutional layer\n",
    "    W_conv1 = weight_variable([3, 3, 1, 64], \"W_conv1\")\n",
    "    b_conv1 = bias_variable([64], \"b_conv1\")\n",
    "\n",
    "    h_conv1 = tf.nn.relu6(conv2d(x, W_conv1) + b_conv1)\n",
    "    \n",
    "    print(h_conv1.get_shape())\n",
    "    \n",
    "    # max pooling \n",
    "    \n",
    "    # 2nd convolutional layer\n",
    "    W_conv1 = weight_variable([3, 3, 1, 64], \"W_conv1\")\n",
    "    b_conv1 = bias_variable([64], \"b_conv1\")\n",
    "\n",
    "    h_conv1 = tf.nn.relu6(conv2d(x, W_conv1) + b_conv1)\n",
    "     \n",
    "    \n",
    "    \n",
    "    #Colorization Network\n",
    "    \n",
    "    #Transposed CNN Layer 1\n",
    "    W_transpose_conv1 = weight_variable([3, 3, 2, 64], \"W_transpose_conv1\")\n",
    "    b_transpose_conv1 = bias_variable([2], \"b_transpose_conv1\")\n",
    "\n",
    "    h_conv_t_4 = conv2d_transpose_strided(h_conv1, W_transpose_conv1) + b_transpose_conv1\n",
    "    \n",
    "    print(h_conv_t_4.get_shape())\n",
    "      \n",
    "    W_last = weight_variable([1, 1, 2, 2], \"W_last\")\n",
    "    b_last = bias_variable([2], \"b_last\")\n",
    "    last_cnn = tf.nn.sigmoid(conv2d(h_conv_t_4, W_last) + b_last, name=\"color_image\")\n",
    "    \n",
    "    print(last_cnn.get_shape())\n",
    "\n",
    "    ''' _lambda = 0.05;\n",
    "    \n",
    "    l1_regularizer = tf.contrib.layers.l1_regularizer(scale=_lambda, scope=None)\n",
    "   \n",
    "    weights = [W_conv1, W_transpose_conv1,  W_last]\n",
    "    \n",
    "    regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, weights)\n",
    "    '''\n",
    "    \n",
    "    #Loss computation\n",
    "    gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(last_cnn - y)) #+ regularization_penalty\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(gen_loss_mse)\n",
    "    \n",
    "    #pred image\n",
    "    tf.add_to_collection('optimizer', optimizer)  \n",
    "    tf.add_to_collection('loss', gen_loss_mse) \n",
    "    tf.add_to_collection('color_image', last_cnn)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Training\n",
    "    for itr in range(hm_epochs):\n",
    "        #image, color_images = get_next_batch(train_features, train_labels)\n",
    "        image, color_images = get_next_batch_from_disk_Nocrop_HSV(images_list=images_list, batch_size=batch_size)\n",
    "        #print(image.shape)\n",
    "        feed_dict = {x: image, y: color_images}\n",
    "        sess.run(optimizer, feed_dict=feed_dict)\n",
    "        \n",
    "        if itr % 100 == 0:\n",
    "            mse = sess.run(gen_loss_mse, feed_dict=feed_dict)\n",
    "            print(\"Step: %d, MSE: %g\" % (itr, mse))\n",
    "     \n",
    "    saver.save(sess, model_path)\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 64)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "Step: 0, MSE: 3.77975e+08\n",
      "Step: 100, MSE: 3.75612e+08\n",
      "Step: 200, MSE: 3.75247e+08\n",
      "Step: 300, MSE: 3.75212e+08\n",
      "Step: 400, MSE: 3.75201e+08\n",
      "Step: 500, MSE: 3.75196e+08\n",
      "Step: 600, MSE: 3.75194e+08\n",
      "Step: 700, MSE: 3.75193e+08\n",
      "Step: 800, MSE: 3.75192e+08\n",
      "Step: 900, MSE: 3.75191e+08\n"
     ]
    }
   ],
   "source": [
    "#Global constants\n",
    "seed = 56\n",
    "\n",
    "#cycles of feed forward + backprop on all K-folded samples\n",
    "hm_epochs = 1000\n",
    "\n",
    "model_path = \"./model/model.ckpt\"\n",
    "save_dir = './model/'\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, 256, 256, 1], name = 'x')\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, 256, 256, 2], name='y')\n",
    "#dropout_prob = tf.placeholder('float', (), name = 'dropout_prob')\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "train_neural_network_colorization_sig(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network_colorization_sig(x):\n",
    "    \n",
    "    strides1 = [1, 1, 1, 1]\n",
    "    strides2 = [1, 2, 2, 1]\n",
    "    \n",
    "    # first convolutional layer\n",
    "    W_conv1 = weight_variable([3, 3, 1, 64], \"W_conv1\")\n",
    "    b_conv1 = bias_variable([64], \"b_conv1\")\n",
    "\n",
    "    h_conv1 = tf.nn.relu6(conv2d(x, W_conv1, strides2) + b_conv1)\n",
    "    \n",
    "    print(h_conv1.get_shape())\n",
    "    \n",
    "    #Second CNN layer\n",
    "    W_conv2 = weight_variable([3, 3, 64, 128], \"W_conv2\")\n",
    "    b_conv2 = bias_variable([128], \"b_conv2\")\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "    \n",
    "    print(h_conv2.get_shape())\n",
    "    \n",
    "    #Third CNN Layer\n",
    "    W_conv3 = weight_variable([3, 3, 128, 128], \"W_conv3\")\n",
    "    b_conv3 = bias_variable([128], \"b_conv3\")\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, strides2) + b_conv3)\n",
    "    \n",
    "    print(h_conv3.get_shape())\n",
    "    \n",
    "    #Fourth CNN Layer\n",
    "    W_conv4 = weight_variable([3, 3, 128, 256], \"W_conv4\")\n",
    "    b_conv4 = bias_variable([256], \"b_conv4\")\n",
    "\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4 ) + b_conv4)\n",
    "    \n",
    "    print(h_conv4.get_shape())\n",
    "    \n",
    "    #Fifth CNN Layer\n",
    "    W_conv5 = weight_variable([3, 3, 256, 256], \"W_conv5\")\n",
    "    b_conv5 = bias_variable([256], \"b_conv5\")\n",
    "\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, strides2) + b_conv5)\n",
    "    \n",
    "    print(h_conv5.get_shape())\n",
    "    \n",
    "    #Sixth CNN Layer\n",
    "    W_conv6 = weight_variable([3, 3, 256, 512], \"W_conv6\")\n",
    "    b_conv6 = bias_variable([512], \"b_conv6\")\n",
    "\n",
    "    h_conv6 = tf.nn.relu(conv2d(h_conv5, W_conv6) + b_conv6)\n",
    "    \n",
    "    print(h_conv6.get_shape())\n",
    "    \n",
    "    #Mid Level features\n",
    "    W_midlvl1 = weight_variable([3, 3, 512, 512], \"W_midlvl1\")\n",
    "    b_midlvl1 = bias_variable([512], \"b_midlvl1\")\n",
    "\n",
    "    h_midlvl1 = tf.nn.relu(conv2d(h_conv6, W_midlvl1) + b_midlvl1)\n",
    "    #h_pool_midlvl1 = max_pool_2x2(h_midlvl1)\n",
    "\n",
    "    print(h_midlvl1.get_shape())\n",
    "    \n",
    "    W_midlvl2 = weight_variable([3, 3, 512, 256], \"W_midlvl2\")\n",
    "    b_midlvl2 = bias_variable([256], \"b_midlvl2\")\n",
    "\n",
    "    h_midlvl2 = tf.nn.relu(conv2d(h_midlvl1, W_midlvl2) + b_midlvl2)\n",
    "\n",
    "    print(h_midlvl2.get_shape())\n",
    "\n",
    "    #Colorization Network\n",
    "    \n",
    "    #Transposed CNN Layer 1\n",
    "    W_transpose_conv1 = weight_variable([3, 3, 128, 256], \"W_transpose_conv1\")\n",
    "    b_transpose_conv1 = bias_variable([128], \"b_transpose_conv1\")\n",
    "\n",
    "    h_conv_t_4 = conv2d_transpose_strided(h_midlvl2, W_transpose_conv1) + b_transpose_conv1\n",
    "    \n",
    "    print(h_conv_t_4.get_shape())\n",
    "    \n",
    "    # CNN conv\n",
    "    \n",
    "    W_colorizer_CNN1 = weight_variable([3, 3, 128 , 128 ], \"W_colorizer_CNN1\")\n",
    "    b_colorizer_CNN1 = bias_variable([128 ], \"b_colorizer_CNN1\")\n",
    "\n",
    "    h_colorizer_conv1 = tf.nn.relu6(conv2d(h_conv_t_4, W_colorizer_CNN1) + b_colorizer_CNN1)\n",
    "    \n",
    "    print(h_colorizer_conv1.get_shape())\n",
    "    \n",
    "\n",
    "    #Transposed CNN Layer 2\n",
    "    W_transpose_conv2 = weight_variable([3, 3, 64, 128], \"W_transpose_conv2\")\n",
    "    b_transpose_conv2 = bias_variable([64], \"b_transpose_conv2\")\n",
    "\n",
    "    h_conv_t_5 = conv2d_transpose_strided(h_colorizer_conv1, W_transpose_conv2) + b_transpose_conv2\n",
    "    \n",
    "    print(h_conv_t_5.get_shape())\n",
    "      \n",
    "    #Transposed CNN Layer 3\n",
    "    W_transpose_conv3 = weight_variable([3, 3, 2, 64], \"W_transpose_conv3\")\n",
    "    b_transpose_conv3 = bias_variable([2], \"b_transpose_conv3\")\n",
    "\n",
    "    h_conv_t_6 = tf.add(conv2d_transpose_strided(h_conv_t_5, W_transpose_conv3), b_transpose_conv3)\n",
    "    \n",
    "    print(h_conv_t_6.get_shape())\n",
    "    \n",
    "    W_last = weight_variable([1, 1, 2, 2], \"W_last\")\n",
    "    b_last = bias_variable([2], \"b_last\")\n",
    "    last_cnn = tf.nn.sigmoid(conv2d(h_conv_t_6, W_last) + b_last, name=\"color_image\")\n",
    "    \n",
    "    print(last_cnn.get_shape())\n",
    "\n",
    "    _lambda = 0.05;\n",
    "    \n",
    "    l1_regularizer = tf.contrib.layers.l1_regularizer(scale=_lambda, scope=None)\n",
    "   \n",
    "    weights = [W_conv1, W_conv2, W_conv3, W_conv4, W_conv5, W_conv6, W_midlvl1, W_midlvl2,\n",
    "                    W_transpose_conv1, W_transpose_conv2, W_last]\n",
    "    \n",
    "    regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, weights)\n",
    "    \n",
    "    #Loss computation\n",
    "    gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(last_cnn - y)) + regularization_penalty\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(gen_loss_mse)\n",
    "    \n",
    "    #pred image\n",
    "    tf.add_to_collection('optimizer', optimizer)  \n",
    "    tf.add_to_collection('loss', gen_loss_mse) \n",
    "    tf.add_to_collection('color_image', last_cnn)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Training\n",
    "    for itr in range(hm_epochs):\n",
    "        #image, color_images = get_next_batch(train_features, train_labels)\n",
    "        image, color_images = get_next_batch_from_disk_Nocrop_HSV_HSV(images_list=images_list, batch_size=batch_size)\n",
    "        #print(image.shape)\n",
    "        feed_dict = {x: image, y: color_images}\n",
    "        sess.run(optimizer, feed_dict=feed_dict)\n",
    "        \n",
    "        if itr % 100 == 0:\n",
    "            mse = sess.run(gen_loss_mse, feed_dict=feed_dict)\n",
    "            print(\"Step: %d, MSE: %g\" % (itr, mse))\n",
    "     \n",
    "    saver.save(sess, model_path)\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network_colorization_sig(x):\n",
    "    \n",
    "    strides1 = [1, 1, 1, 1]\n",
    "    strides2 = [1, 2, 2, 1]\n",
    "    \n",
    "    # first convolutional layer\n",
    "    W_conv1 = weight_variable([3, 3, 1, 64], \"W_conv1\")\n",
    "    b_conv1 = bias_variable([64], \"b_conv1\")\n",
    "\n",
    "    h_conv1 = tf.nn.relu6(conv2d(x, W_conv1, strides2) + b_conv1)\n",
    "    \n",
    "    print(h_conv1.get_shape())\n",
    "    \n",
    "    #Second CNN layer\n",
    "    W_conv2 = weight_variable([3, 3, 64, 128], \"W_conv2\")\n",
    "    b_conv2 = bias_variable([128], \"b_conv2\")\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "    \n",
    "    print(h_conv2.get_shape())\n",
    "    \n",
    "    #Third CNN Layer\n",
    "    W_conv3 = weight_variable([3, 3, 128, 128], \"W_conv3\")\n",
    "    b_conv3 = bias_variable([128], \"b_conv3\")\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, strides2) + b_conv3)\n",
    "    \n",
    "    print(h_conv3.get_shape())\n",
    "    \n",
    "    #Fourth CNN Layer\n",
    "    W_conv4 = weight_variable([3, 3, 128, 256], \"W_conv4\")\n",
    "    b_conv4 = bias_variable([256], \"b_conv4\")\n",
    "\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4 ) + b_conv4)\n",
    "    \n",
    "    print(h_conv4.get_shape())\n",
    "    \n",
    "    #Fifth CNN Layer\n",
    "    W_conv5 = weight_variable([3, 3, 256, 256], \"W_conv5\")\n",
    "    b_conv5 = bias_variable([256], \"b_conv5\")\n",
    "\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, strides2) + b_conv5)\n",
    "    \n",
    "    print(h_conv5.get_shape())\n",
    "    \n",
    "    #Sixth CNN Layer\n",
    "    W_conv6 = weight_variable([3, 3, 256, 512], \"W_conv6\")\n",
    "    b_conv6 = bias_variable([512], \"b_conv6\")\n",
    "\n",
    "    h_conv6 = tf.nn.relu(conv2d(h_conv5, W_conv6) + b_conv6)\n",
    "    \n",
    "    print(h_conv6.get_shape())\n",
    "    \n",
    "    #Mid Level features\n",
    "    W_midlvl1 = weight_variable([3, 3, 512, 512], \"W_midlvl1\")\n",
    "    b_midlvl1 = bias_variable([512], \"b_midlvl1\")\n",
    "\n",
    "    h_midlvl1 = tf.nn.relu(conv2d(h_conv6, W_midlvl1) + b_midlvl1)\n",
    "    #h_pool_midlvl1 = max_pool_2x2(h_midlvl1)\n",
    "\n",
    "    print(h_midlvl1.get_shape())\n",
    "    \n",
    "    W_midlvl2 = weight_variable([3, 3, 512, 256], \"W_midlvl2\")\n",
    "    b_midlvl2 = bias_variable([256], \"b_midlvl2\")\n",
    "\n",
    "    h_midlvl2 = tf.nn.relu(conv2d(h_midlvl1, W_midlvl2) + b_midlvl2)\n",
    "\n",
    "    print(h_midlvl2.get_shape())\n",
    "\n",
    "    #Colorization Network\n",
    "    \n",
    "    #Transposed CNN Layer 1\n",
    "    W_transpose_conv1 = weight_variable([3, 3, 128, 256], \"W_transpose_conv1\")\n",
    "    b_transpose_conv1 = bias_variable([128], \"b_transpose_conv1\")\n",
    "\n",
    "    h_conv_t_4 = conv2d_transpose_strided(h_midlvl2, W_transpose_conv1) + b_transpose_conv1\n",
    "    \n",
    "    print(h_conv_t_4.get_shape())\n",
    "    \n",
    "    # CNN conv\n",
    "    \n",
    "    W_colorizer_CNN1 = weight_variable([3, 3, 128 , 128 ], \"W_colorizer_CNN1\")\n",
    "    b_colorizer_CNN1 = bias_variable([128 ], \"b_colorizer_CNN1\")\n",
    "\n",
    "    h_colorizer_conv1 = tf.nn.relu6(conv2d(h_conv_t_4, W_colorizer_CNN1) + b_colorizer_CNN1)\n",
    "    \n",
    "    print(h_colorizer_conv1.get_shape())\n",
    "    \n",
    "\n",
    "    #Transposed CNN Layer 2\n",
    "    W_transpose_conv2 = weight_variable([3, 3, 64, 128], \"W_transpose_conv2\")\n",
    "    b_transpose_conv2 = bias_variable([64], \"b_transpose_conv2\")\n",
    "\n",
    "    h_conv_t_5 = conv2d_transpose_strided(h_colorizer_conv1, W_transpose_conv2) + b_transpose_conv2\n",
    "    \n",
    "    print(h_conv_t_5.get_shape())\n",
    "      \n",
    "    #Transposed CNN Layer 3\n",
    "    W_transpose_conv3 = weight_variable([3, 3, 3, 64], \"W_transpose_conv3\")\n",
    "    b_transpose_conv3 = bias_variable([3], \"b_transpose_conv3\")\n",
    "\n",
    "    h_conv_t_6 = tf.add(conv2d_transpose_strided(h_conv_t_5, W_transpose_conv3), b_transpose_conv3)\n",
    "    \n",
    "    print(h_conv_t_6.get_shape())\n",
    "    \n",
    "    W_last = weight_variable([1, 1, 3, 3], \"W_last\")\n",
    "    b_last = bias_variable([3], \"b_last\")\n",
    "    last_cnn = tf.nn.sigmoid(conv2d(h_conv_t_6, W_last) + b_last, name=\"color_image\")\n",
    "    \n",
    "    print(last_cnn.get_shape())\n",
    "\n",
    "    #to_save = [W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3, W_transpose_conv1, b_transpose_conv1, W_transpose_conv2, b_transpose_conv2, W_transpose_conv3, b_transpose_conv3]    \n",
    "    \n",
    "    _lambda = 0.005;\n",
    "  \n",
    "    \n",
    "    l1_regularizer = tf.contrib.layers.l1_regularizer(scale=_lambda, scope=None)\n",
    "   \n",
    "    weights = [W_conv1, W_conv2, W_conv3, W_conv4, W_conv5, W_conv6, W_midlvl1, W_midlvl2,\n",
    "                    W_transpose_conv1, W_transpose_conv2, W_last]\n",
    "    \n",
    "    regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, weights)\n",
    "    \n",
    "    #Loss computation\n",
    "    gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(last_cnn - y)) + regularization_penalty\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(gen_loss_mse)\n",
    "    \n",
    "    #pred image\n",
    "    tf.add_to_collection('optimizer', optimizer)  \n",
    "    tf.add_to_collection('loss', gen_loss_mse) \n",
    "    tf.add_to_collection('color_image', last_cnn)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Training\n",
    "    for itr in range(hm_epochs):\n",
    "        #image, color_images = get_next_batch(train_features, train_labels)\n",
    "        image, color_images = get_next_batch_from_disk_RGB_Nocrop(images_list=images_list, batch_size=batch_size)\n",
    "        #print(image.shape)\n",
    "        feed_dict = {x: image, y: color_images}\n",
    "        sess.run(optimizer, feed_dict=feed_dict)\n",
    "        \n",
    "        if itr % 100 == 0:\n",
    "            mse = sess.run(gen_loss_mse, feed_dict=feed_dict)\n",
    "            print(\"Step: %d, MSE: %g\" % (itr, mse))\n",
    "     \n",
    "    saver.save(sess, model_path)\n",
    "    \n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
