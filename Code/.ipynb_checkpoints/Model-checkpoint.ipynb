{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#Vers. 1.0.0\n",
    "print(tf.__version__)\n",
    "import sys\n",
    "#Should be above 3.5\n",
    "#print (sys.version)     \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import color\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from Helpers import get_files, load_image, separate_imgs, get_next_batch_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_list = get_files(\"..\\Data\\Images\\\\*\", '*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Building the Training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1, seed=seed, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "#From https://github.com/shekkizh/Colorization.tensorflow/blob/master/TensorflowUtils.py\n",
    "def conv2d_transpose_strided(x, W, output_shape=None, stride=2):\n",
    "    #print (x.get_shape())\n",
    "    #print (W.get_shape())\n",
    "    if output_shape is None:\n",
    "        output_shape = x.get_shape().as_list()\n",
    "        output_shape[1] *= 2\n",
    "        output_shape[2] *= 2\n",
    "        output_shape[3] = W.get_shape().as_list()[2]\n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Global constants\n",
    "seed = 678\n",
    "\n",
    "#cycles of feed forward + backprop on all K-folded samples\n",
    "hm_epochs = 20\n",
    "\n",
    "model_path = \"./batch16/model.ckpt\"\n",
    "save_dir = './batch16/'\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, 360, 640, 3], name = 'x')\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, 360, 640, 3], name='y')\n",
    "#dropout_prob = tf.placeholder('float', (), name = 'dropout_prob')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "    # first convolutional layer\n",
    "    W_conv1 = weight_variable([5, 5, 3, 64], \"W_conv1\")\n",
    "    b_conv1 = bias_variable([64], \"b_conv1\")\n",
    "\n",
    "    h_conv1 = tf.nn.relu6(conv2d(x, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    print(h_pool1.get_shape())\n",
    "    \n",
    "    #Second CNN layer\n",
    "    W_conv2 = weight_variable([5, 5, 64, 128], \"W_conv2\")\n",
    "    b_conv2 = bias_variable([128], \"b_conv2\")\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    \n",
    "    print(h_pool2.get_shape())\n",
    "    \n",
    "    #Third CNN Layer\n",
    "    W_conv3 = weight_variable([5, 5, 128, 256], \"W_conv3\")\n",
    "    b_conv3 = bias_variable([256], \"b_conv3\")\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "    h_pool3 = max_pool_2x2(h_conv3)\n",
    "    \n",
    "    print(h_pool3.get_shape())\n",
    "    \n",
    "    #Colorization Network\n",
    "    #Transposed CNN Layer 1\n",
    "    W_transpose_conv1 = weight_variable([5, 5, 128, 256], \"W_transpose_conv1\")\n",
    "    b_transpose_conv1 = bias_variable([128], \"b_transpose_conv1\")\n",
    "\n",
    "    h_conv4 = conv2d_transpose_strided(h_pool3, W_transpose_conv1) + b_transpose_conv1\n",
    "    \n",
    "    print(h_conv4.get_shape())\n",
    "  \n",
    "    #Transposed CNN Layer 2\n",
    "    W_transpose_conv2 = weight_variable([5, 5, 64, 128], \"W_transpose_conv2\")\n",
    "    b_transpose_conv2 = bias_variable([64], \"b_transpose_conv2\")\n",
    "\n",
    "    h_conv5 = conv2d_transpose_strided(h_conv4, W_transpose_conv2) + b_transpose_conv2\n",
    "    \n",
    "    print(h_conv5.get_shape())\n",
    "      \n",
    "    #Transposed CNN Layer 3\n",
    "    W_transpose_conv3 = weight_variable([5, 5, 3, 64], \"W_transpose_conv3\")\n",
    "    b_transpose_conv3 = bias_variable([3], \"b_transpose_conv3\")\n",
    "\n",
    "    h_conv6 = tf.add(conv2d_transpose_strided(h_conv5, W_transpose_conv3), b_transpose_conv3, name=\"color_image\")\n",
    "      \n",
    "    #to_save = [W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3, W_transpose_conv1, b_transpose_conv1, W_transpose_conv2, b_transpose_conv2, W_transpose_conv3, b_transpose_conv3]    \n",
    "    \n",
    "    #Loss computation\n",
    "    gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(h_conv6 - y))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(gen_loss_mse)\n",
    "    \n",
    "    #pred image\n",
    "    \n",
    "    tf.add_to_collection('optimizer', optimizer)  \n",
    "    tf.add_to_collection('loss', gen_loss_mse) \n",
    "    tf.add_to_collection('bias_test', b_conv1)\n",
    "    tf.add_to_collection('color_image', h_conv6)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Training\n",
    "    for itr in range(hm_epochs):\n",
    "        #image, color_images = get_next_batch(train_features, train_labels)\n",
    "        image, color_images = get_next_batch_from_disk(images_list=images_list, batch_size=batch_size)\n",
    "        feed_dict = {x: image, y: color_images}\n",
    "\n",
    "        if itr % 10 == 0:\n",
    "            mse = sess.run(gen_loss_mse, feed_dict=feed_dict)\n",
    "            sess.run(optimizer, feed_dict=feed_dict)\n",
    "            print(\"Step: %d, MSE: %g\" % (itr, mse))\n",
    "     \n",
    "    saver.save(sess, model_path)\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 180, 320, 64)\n",
      "(16, 90, 160, 128)\n",
      "(16, 45, 80, 256)\n",
      "(16, 90, 160, 128)\n",
      "(16, 180, 320, 64)\n",
      "Step: 0, MSE: 5.05871e+10\n",
      "Step: 10, MSE: 1.56348e+10\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network2(x):\n",
    "    # first convolutional layer\n",
    "    W_conv1 = weight_variable([5, 5, 3, 64], \"W_conv1\")\n",
    "    b_conv1 = bias_variable([64], \"b_conv1\")\n",
    "\n",
    "    h_conv1 = tf.nn.relu6(conv2d(x, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    print(h_pool1.get_shape())\n",
    "    \n",
    "    #Second CNN layer\n",
    "    W_conv2 = weight_variable([5, 5, 64, 128], \"W_conv2\")\n",
    "    b_conv2 = bias_variable([128], \"b_conv2\")\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    \n",
    "    print(h_pool2.get_shape())\n",
    "    \n",
    "    #Third CNN Layer\n",
    "    W_conv3 = weight_variable([5, 5, 128, 256], \"W_conv3\")\n",
    "    b_conv3 = bias_variable([256], \"b_conv3\")\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "    h_pool3 = max_pool_2x2(h_conv3)\n",
    "    \n",
    "    print(h_pool3.get_shape())\n",
    "    \n",
    "    #Colorization Network\n",
    "    #Transposed CNN Layer 1\n",
    "    W_transpose_conv1 = weight_variable([5, 5, 128, 256], \"W_transpose_conv1\")\n",
    "    b_transpose_conv1 = bias_variable([128], \"b_transpose_conv1\")\n",
    "\n",
    "    h_conv4 = conv2d_transpose_strided(h_pool3, W_transpose_conv1) + b_transpose_conv1\n",
    "    \n",
    "    print(h_conv4.get_shape())\n",
    "  \n",
    "    #Transposed CNN Layer 2\n",
    "    W_transpose_conv2 = weight_variable([5, 5, 64, 128], \"W_transpose_conv2\")\n",
    "    b_transpose_conv2 = bias_variable([64], \"b_transpose_conv2\")\n",
    "\n",
    "    h_conv5 = conv2d_transpose_strided(h_conv4, W_transpose_conv2) + b_transpose_conv2\n",
    "    \n",
    "    print(h_conv5.get_shape())\n",
    "      \n",
    "    #Transposed CNN Layer 3\n",
    "    W_transpose_conv3 = weight_variable([5, 5, 3, 64], \"W_transpose_conv3\")\n",
    "    b_transpose_conv3 = bias_variable([3], \"b_transpose_conv3\")\n",
    "\n",
    "    h_conv6 = tf.add(conv2d_transpose_strided(h_conv5, W_transpose_conv3), b_transpose_conv3, name=\"color_image\")\n",
    "      \n",
    "    #to_save = [W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3, W_transpose_conv1, b_transpose_conv1, W_transpose_conv2, b_transpose_conv2, W_transpose_conv3, b_transpose_conv3]    \n",
    "    \n",
    "    #Loss computation\n",
    "    gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(h_conv6 - y))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(gen_loss_mse)\n",
    "    \n",
    "    #pred image\n",
    "    \n",
    "    tf.add_to_collection('optimizer', optimizer)  \n",
    "    tf.add_to_collection('loss', gen_loss_mse) \n",
    "    tf.add_to_collection('bias_test', b_conv1)\n",
    "    tf.add_to_collection('color_image', h_conv6)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Training\n",
    "    for itr in range(hm_epochs):\n",
    "        #image, color_images = get_next_batch(train_features, train_labels)\n",
    "        image, color_images = get_next_batch_from_disk(images_list=images_list, batch_size=batch_size)\n",
    "        feed_dict = {x: image, y: color_images}\n",
    "\n",
    "        if itr % 10 == 0:\n",
    "            mse = sess.run(gen_loss_mse, feed_dict=feed_dict)\n",
    "            sess.run(optimizer, feed_dict=feed_dict)\n",
    "            print(\"Step: %d, MSE: %g\" % (itr, mse))\n",
    "     \n",
    "    saver.save(sess, model_path)\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "train_neural_network2(x)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
