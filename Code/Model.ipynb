{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#Vers. 1.0.0\n",
    "print(tf.__version__)\n",
    "import sys\n",
    "#Should be above 3.5\n",
    "#print (sys.version)     \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import color\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "from Helpers import get_files, load_image, separate_imgs, get_next_batch_from_disk_RGB, get_next_batch_from_disk_RGB_Nocrop, get_next_batch_from_disk_RGB_Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_list = get_files(\"../Data/Extracted/*\", '*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35950"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_list_test = get_files(\"../Data/Extracted/Test/\", '*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Building the Training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1, seed=seed, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(scope, x, kernel_size, stride=1):\n",
    "    W = weight_variable(kernel_size, \"conv_W_\" + scope)\n",
    "    b = bias_variable(kernel_size[3:], \"conv_b_\" + scope)\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    return  tf.nn.relu(conv +  b)\n",
    "\n",
    "#From https://github.com/shekkizh/Colorization.tensorflow/blob/master/TensorflowUtils.py\n",
    "def conv2d_transpose_strided(scope, x, kernel_size, stride=2, output_shape=None):\n",
    "    W = weight_variable(kernel_size, \"deconv_W_\" + scope)\n",
    "    b = bias_variable(kernel_size[3:], \"deconv_b_\" + scope)\n",
    "    \n",
    "    if output_shape is None:\n",
    "        output_shape = x.get_shape().as_list()\n",
    "        output_shape[1] *= 2\n",
    "        output_shape[2] *= 2\n",
    "        output_shape[3] = W.get_shape().as_list()[2]\n",
    "        \n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "def batch_norm(scope, x, train=True, reuse=False):\n",
    "    return tf.contrib.layers.batch_norm(x, center=True, scale=True, updates_collections=None, is_training=train, trainable=True, scope=scope)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_neural_network_colorization_nilboyarch(x):\n",
    "    \n",
    "    #conv1\n",
    "    conv_num = 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), x, [3, 3, 1, 64], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 64, 64], stride=2)\n",
    "    conv_num += 1\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "\n",
    "    #self.nilboy = temp_conv\n",
    "\n",
    "    temp_conv = batch_norm('bn_1', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    #conv2\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 64, 128], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 128, 128], stride=2)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = batch_norm('bn_2', temp_conv,train=is_training)\n",
    "    \n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    #conv3\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 128, 256], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 256, 256], stride=1)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 256, 256], stride=2)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = batch_norm('bn_3', temp_conv, train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    \n",
    "    #conv4\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 256, 512], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    \n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = batch_norm('bn_4', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "\n",
    "    #conv5\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = batch_norm('bn_5', temp_conv,train=is_training)\n",
    "    \n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    #conv6\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = batch_norm('bn_6', temp_conv,train=is_training) \n",
    "    \n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    #conv7\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 512, 512], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = batch_norm('bn_7', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    \n",
    "    #Dropout layer for OF\n",
    "    temp_conv = tf.nn.dropout(temp_conv, keep_prob)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    \n",
    "    #conv8\n",
    "    temp_conv = conv2d_transpose_strided('conv' + str(conv_num), temp_conv, [4, 4, 256, 512], stride=2)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 256, 256], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 256, 256], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = batch_norm('bn_8', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "\n",
    "    \n",
    "    #conv9\n",
    "    temp_conv = conv2d_transpose_strided('conv' + str(conv_num), temp_conv, [3, 3, 128, 256], stride=2)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 128, 128], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 128, 128], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = batch_norm('bn_9', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    #conv10\n",
    "    temp_conv = conv2d_transpose_strided('conv' + str(conv_num), temp_conv, [3, 3, 64, 128], stride=2)\n",
    "    conv_num += 1    \n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 64, 64], stride=1)\n",
    "    conv_num += 1\n",
    "\n",
    "    temp_conv = conv2d('conv' + str(conv_num), temp_conv, [3, 3, 64, 64], stride=1)\n",
    "    conv_num += 1\n",
    "    \n",
    "    temp_conv = batch_norm('bn_10', temp_conv,train=is_training)\n",
    "    \n",
    "    print(temp_conv.get_shape())\n",
    "    \n",
    "    W_last = weight_variable([3, 3, 64, 3], 'conv_W_last')\n",
    "    b_last = bias_variable([3], 'conv_b_last')\n",
    "    last_cnn = tf.nn.sigmoid(tf.nn.conv2d(temp_conv, W_last, strides=[1, 1, 1, 1], padding='SAME') )\n",
    "    print(last_cnn.get_shape())\n",
    "    \n",
    "    \n",
    "    _lambda = 0.05;\n",
    "    l1_regularizer = tf.contrib.layers.l1_regularizer(scale=_lambda, scope=None)\n",
    "    regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "    \n",
    "    \n",
    "    #Loss computation\n",
    "    gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(last_cnn - y)) + regularization_penalty\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(gen_loss_mse)\n",
    "    \n",
    "    #pred image\n",
    "    tf.add_to_collection('optimizer', optimizer)  \n",
    "    tf.add_to_collection('loss', gen_loss_mse) \n",
    "    tf.add_to_collection('color_image', last_cnn)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Training\n",
    "    for itr in range(hm_epochs):\n",
    "        #image, color_images = get_next_batch(train_features, train_labels)\n",
    "        image, color_images = get_next_batch_from_disk_RGB_Gaussian(images_list=images_list, batch_size=batch_size, crop_size=224)\n",
    "        #print(image.shape)\n",
    "        feed_dict = {x: image, y: color_images, keep_prob: dropout_keep_prob, is_training : True}\n",
    "        \n",
    "\n",
    "        sess.run(optimizer, feed_dict=feed_dict)\n",
    "        \n",
    "        if itr % 20 == 0:\n",
    "            \n",
    "            image_test, color_images_test = get_next_batch_from_disk_RGB_Gaussian(images_list=images_list_test, batch_size=batch_size, crop_size=224)\n",
    "            feed_dict_test = {x: image_test, y: color_images_test, keep_prob: 1.0, is_training : False}\n",
    "            \n",
    "            mse = sess.run(gen_loss_mse, feed_dict=feed_dict_test)\n",
    "            sess.run(optimizer, feed_dict=feed_dict)\n",
    "            print(\"Step: %d, MSE: %g\" % (itr, mse))\n",
    "     \n",
    "    saver.save(sess, model_path)\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 112, 112, 64)\n",
      "(15, 112, 112, 64)\n",
      "(15, 56, 56, 128)\n",
      "(15, 28, 28, 256)\n",
      "(15, 28, 28, 512)\n",
      "(15, 28, 28, 512)\n",
      "(15, 28, 28, 512)\n",
      "(15, 28, 28, 512)\n",
      "(15, 28, 28, 512)\n",
      "(15, 56, 56, 256)\n",
      "(15, 112, 112, 128)\n",
      "(15, 224, 224, 64)\n",
      "(15, 224, 224, 3)\n",
      "Step: 0, MSE: 938652\n",
      "Step: 20, MSE: 953446\n"
     ]
    }
   ],
   "source": [
    "#Global constants\n",
    "seed = 56\n",
    "\n",
    "#cycles of feed forward + backprop on all K-folded samples\n",
    "hm_epochs = 40\n",
    "dropout_keep_prob = 0.5\n",
    "\n",
    "model_path = \"./recent/model.ckpt\"\n",
    "save_dir = './recent/'\n",
    "\n",
    "batch_size = 15\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, 224, 224, 1], name = 'x')\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, 224, 224, 3], name='y')\n",
    "keep_prob = tf.placeholder(tf.float32, name = 'keep_prob')\n",
    "is_training = tf.placeholder(tf.bool, name = 'is_training');\n",
    "#dropout_prob = tf.placeholder('float', (), name = 'dropout_prob')\n",
    "\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "train_neural_network_colorization_nilboyarch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "def weight_variable(shape, name, dropout=1):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1, seed=seed, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, strides=[1,1,1,1]):\n",
    "    return tf.nn.conv2d(x, W, strides=strides, padding='SAME')\n",
    "\n",
    "#From https://github.com/shekkizh/Colorization.tensorflow/blob/master/TensorflowUtils.py\n",
    "def conv2d_transpose_strided(x, W, output_shape=None, stride=2):\n",
    "    #print (x.get_shape())\n",
    "    #print (W.get_shape())\n",
    "    if output_shape is None:\n",
    "        output_shape = x.get_shape().as_list()\n",
    "        output_shape[1] *= 2\n",
    "        output_shape[2] *= 2\n",
    "        output_shape[3] = W.get_shape().as_list()[2]\n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "def batch_norm(scope, x, train=True, reuse=False):\n",
    "    return tf.contrib.layers.batch_norm(x, center=True, scale=True, updates_collections=None, is_training=train, trainable=True, scope=scope)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_neural_network_colorization_sig(x):\n",
    "    \n",
    "    strides1 = [1, 1, 1, 1]\n",
    "    strides2 = [1, 2, 2, 1]\n",
    "    \n",
    "    # first convolutional layer\n",
    "    W_conv1 = weight_variable([3, 3, 1, 64], \"W_conv1\")\n",
    "    b_conv1 = bias_variable([64], \"b_conv1\")\n",
    "\n",
    "    h_conv1 = tf.nn.relu6(conv2d(x, W_conv1, strides2) + b_conv1)\n",
    "    \n",
    "    print(h_conv1.get_shape())\n",
    "    \n",
    "    #Second CNN layer\n",
    "    W_conv2 = weight_variable([3, 3, 64, 128], \"W_conv2\")\n",
    "    b_conv2 = bias_variable([128], \"b_conv2\")\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "    \n",
    "    print(h_conv2.get_shape())\n",
    "    \n",
    "    #Third CNN Layer\n",
    "    W_conv3 = weight_variable([3, 3, 128, 128], \"W_conv3\")\n",
    "    b_conv3 = bias_variable([128], \"b_conv3\")\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, strides2) + b_conv3)\n",
    "    \n",
    "    print(h_conv3.get_shape())\n",
    "    \n",
    "    #Fourth CNN Layer\n",
    "    W_conv4 = weight_variable([3, 3, 128, 256], \"W_conv4\")\n",
    "    b_conv4 = bias_variable([256], \"b_conv4\")\n",
    "\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4 ) + b_conv4)\n",
    "    \n",
    "    print(h_conv4.get_shape())\n",
    "    \n",
    "    #Fifth CNN Layer\n",
    "    W_conv5 = weight_variable([3, 3, 256, 256], \"W_conv5\")\n",
    "    b_conv5 = bias_variable([256], \"b_conv5\")\n",
    "\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, strides2) + b_conv5)\n",
    "    \n",
    "    print(h_conv5.get_shape())\n",
    "    \n",
    "    #Sixth CNN Layer\n",
    "    W_conv6 = weight_variable([3, 3, 256, 512], \"W_conv6\")\n",
    "    b_conv6 = bias_variable([512], \"b_conv6\")\n",
    "\n",
    "    h_conv6 = tf.nn.relu(conv2d(h_conv5, W_conv6) + b_conv6)\n",
    "    \n",
    "    print(h_conv6.get_shape())\n",
    "    \n",
    "    #Mid Level features\n",
    "    W_midlvl1 = weight_variable([3, 3, 512, 512], \"W_midlvl1\")\n",
    "    b_midlvl1 = bias_variable([512], \"b_midlvl1\")\n",
    "\n",
    "    h_midlvl1 = tf.nn.relu(conv2d(h_conv6, W_midlvl1) + b_midlvl1)\n",
    "    #h_pool_midlvl1 = max_pool_2x2(h_midlvl1)\n",
    "\n",
    "    print(h_midlvl1.get_shape())\n",
    "    \n",
    "    W_midlvl2 = weight_variable([3, 3, 512, 256], \"W_midlvl2\")\n",
    "    b_midlvl2 = bias_variable([256], \"b_midlvl2\")\n",
    "\n",
    "    h_midlvl2 = tf.nn.relu(conv2d(h_midlvl1, W_midlvl2) + b_midlvl2)\n",
    "\n",
    "    print(h_midlvl2.get_shape())\n",
    "    \n",
    "    #Dropout layer\n",
    "    h_drop = tf.nn.dropout(h_midlvl2, keep_prob)\n",
    "\n",
    "    #Colorization Network\n",
    "    \n",
    "    #Transposed CNN Layer 1\n",
    "    W_transpose_conv1 = weight_variable([3, 3, 128, 256], \"W_transpose_conv1\")\n",
    "    b_transpose_conv1 = bias_variable([128], \"b_transpose_conv1\")\n",
    "\n",
    "    h_conv_t_4 = conv2d_transpose_strided(h_drop, W_transpose_conv1) + b_transpose_conv1\n",
    "    \n",
    "    print(h_conv_t_4.get_shape())\n",
    "    \n",
    "    # CNN conv\n",
    "    \n",
    "    W_colorizer_CNN1 = weight_variable([3, 3, 128 , 128 ], \"W_colorizer_CNN1\")\n",
    "    b_colorizer_CNN1 = bias_variable([128 ], \"b_colorizer_CNN1\")\n",
    "\n",
    "    h_colorizer_conv1 = tf.nn.relu6(conv2d(h_conv_t_4, W_colorizer_CNN1) + b_colorizer_CNN1)\n",
    "    \n",
    "    print(h_colorizer_conv1.get_shape())\n",
    "\n",
    "    #Transposed CNN Layer 2\n",
    "    W_transpose_conv2 = weight_variable([3, 3, 64, 128], \"W_transpose_conv2\")\n",
    "    b_transpose_conv2 = bias_variable([64], \"b_transpose_conv2\")\n",
    "\n",
    "    h_conv_t_5 = conv2d_transpose_strided(h_colorizer_conv1, W_transpose_conv2) + b_transpose_conv2\n",
    "    \n",
    "    print(h_conv_t_5.get_shape())\n",
    "      \n",
    "    #Transposed CNN Layer 3\n",
    "    W_transpose_conv3 = weight_variable([3, 3, 3, 64], \"W_transpose_conv3\")\n",
    "    b_transpose_conv3 = bias_variable([3], \"b_transpose_conv3\")\n",
    "\n",
    "    h_conv_t_6 = tf.add(conv2d_transpose_strided(h_conv_t_5, W_transpose_conv3), b_transpose_conv3)\n",
    "    \n",
    "    print(h_conv_t_6.get_shape())\n",
    "    \n",
    "    W_last = weight_variable([3, 3, 3, 3], \"W_last\")\n",
    "    b_last = bias_variable([3], \"b_last\")\n",
    "    last_cnn = tf.nn.sigmoid(conv2d(h_conv_t_6, W_last) + b_last, name=\"color_image\")\n",
    "    \n",
    "    print(last_cnn.get_shape())\n",
    "    \n",
    "    \n",
    "    #to_save = [W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3, W_transpose_conv1, b_transpose_conv1, W_transpose_conv2, b_transpose_conv2, W_transpose_conv3, b_transpose_conv3]    \n",
    "    \n",
    "    '''_lambda = 0;\n",
    "  \n",
    "    \n",
    "    l1_regularizer = tf.contrib.layers.l1_regularizer(scale=_lambda, scope=None)\n",
    "   \n",
    "    weights = [W_conv1, W_conv2, W_conv3, W_conv4, W_conv5, W_conv6, W_midlvl1, W_midlvl2,\n",
    "                    W_transpose_conv1, W_colorizer_CNN1, W_transpose_conv2, W_transpose_conv3, W_last]\n",
    "    \n",
    "    regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, weights)\n",
    "    '''\n",
    "    \n",
    "    #Loss computation\n",
    "    gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(last_cnn - y)) #+ regularization_penalty\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(gen_loss_mse)\n",
    "    \n",
    "    #pred image\n",
    "    tf.add_to_collection('optimizer', optimizer)  \n",
    "    tf.add_to_collection('loss', gen_loss_mse) \n",
    "    tf.add_to_collection('color_image', last_cnn)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Training\n",
    "    for itr in range(hm_epochs):\n",
    "        #image, color_images = get_next_batch(train_features, train_labels)\n",
    "        image, color_images = get_next_batch_from_disk_RGB(images_list=images_list, batch_size=batch_size)\n",
    "        #print(image.shape)\n",
    "        feed_dict = {x: image, y: color_images, keep_prob: dropout_keep_prob}\n",
    "        sess.run(optimizer, feed_dict=feed_dict)\n",
    "        \n",
    "        if itr % 100 == 0:\n",
    "            mse = sess.run(gen_loss_mse, feed_dict=feed_dict)\n",
    "            sess.run(optimizer, feed_dict=feed_dict)\n",
    "            print(\"Step: %d, MSE: %g\" % (itr, mse))\n",
    "     \n",
    "    saver.save(sess, model_path)\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 32, 32, 64)\n",
      "(80, 32, 32, 128)\n",
      "(80, 16, 16, 128)\n",
      "(80, 16, 16, 256)\n",
      "(80, 8, 8, 256)\n",
      "(80, 8, 8, 512)\n",
      "(80, 8, 8, 512)\n",
      "(80, 8, 8, 256)\n",
      "(80, 16, 16, 128)\n",
      "(80, 16, 16, 128)\n",
      "(80, 32, 32, 64)\n",
      "(80, 64, 64, 3)\n",
      "(80, 64, 64, 3)\n",
      "Step: 0, MSE: 163609\n",
      "Step: 100, MSE: 58441.2\n",
      "Step: 200, MSE: 54213.9\n",
      "Step: 300, MSE: 53787.1\n",
      "Step: 400, MSE: 56334.3\n",
      "Step: 500, MSE: 51149.2\n",
      "Step: 600, MSE: 56110.1\n",
      "Step: 700, MSE: 49822.7\n",
      "Step: 800, MSE: 52687.2\n",
      "Step: 900, MSE: 51984.4\n"
     ]
    }
   ],
   "source": [
    "#Global constants\n",
    "seed = 56\n",
    "\n",
    "#cycles of feed forward + backprop on all K-folded samples\n",
    "hm_epochs = 1000\n",
    "dropout_keep_prob = 0.5\n",
    "\n",
    "model_path = \"./test3/model.ckpt\"\n",
    "save_dir = './test3/'\n",
    "\n",
    "batch_size = 80\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, 64, 64, 1], name = 'x')\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, 64, 64, 3], name='y')\n",
    "keep_prob = tf.placeholder(tf.float32, name = 'keep_prob')\n",
    "#dropout_prob = tf.placeholder('float', (), name = 'dropout_prob')\n",
    "\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "train_neural_network_colorization_sig(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 182, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, color_images = get_next_batch_from_disk_RGB(images_list=images_list, batch_size=batch_size)\n",
    "color_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "#tf.contrib.layers.apply_regularization(tf.contrib.layers.l1_regularizer(_lambda), weights_list=\n",
    "#                                     [W_conv1, W_conv2, ])\n",
    "#vars1  = tf.trainable_variables() \n",
    "#lossL2 = tf.add_n([ tf.nn.l2_loss(v) for v in vars1\n",
    "            #if 'bias' not in v.name ]) * _lambda\n",
    "\n",
    "\n",
    "#weights = [v for v in tf.trainable_variables() if 'bias' not in v.name]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network_colorization_sig2(x):\n",
    "    \n",
    "    strides1 = [1, 1, 1, 1]\n",
    "    strides2 = [1, 2, 2, 1]\n",
    "    \n",
    "    # first convolutional layer\n",
    "    W_conv1 = weight_variable([3, 3, 1, 64], \"W_conv1\")\n",
    "    b_conv1 = bias_variable([64], \"b_conv1\")\n",
    "\n",
    "    h_conv1 = tf.nn.relu6(conv2d(x, W_conv1, strides2) + b_conv1)\n",
    "    \n",
    "    print(h_conv1.get_shape())\n",
    "    \n",
    "    #Second CNN layer\n",
    "    W_conv2 = weight_variable([3, 3, 64, 128], \"W_conv2\")\n",
    "    b_conv2 = bias_variable([128], \"b_conv2\")\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "    \n",
    "    print(h_conv2.get_shape())\n",
    "    \n",
    "    #Third CNN Layer\n",
    "    W_conv3 = weight_variable([3, 3, 128, 128], \"W_conv3\")\n",
    "    b_conv3 = bias_variable([128], \"b_conv3\")\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, strides2) + b_conv3)\n",
    "    \n",
    "    print(h_conv3.get_shape())\n",
    "    \n",
    "    #Fourth CNN Layer\n",
    "    W_conv4 = weight_variable([3, 3, 128, 256], \"W_conv4\")\n",
    "    b_conv4 = bias_variable([256], \"b_conv4\")\n",
    "\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4 ) + b_conv4)\n",
    "    \n",
    "    print(h_conv4.get_shape())\n",
    "    \n",
    "    #Fifth CNN Layer\n",
    "    W_conv5 = weight_variable([3, 3, 256, 256], \"W_conv5\")\n",
    "    b_conv5 = bias_variable([256], \"b_conv5\")\n",
    "\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, strides2) + b_conv5)\n",
    "    \n",
    "    print(h_conv5.get_shape())\n",
    "    \n",
    "    #Sixth CNN Layer\n",
    "    W_conv6 = weight_variable([3, 3, 256, 512], \"W_conv6\")\n",
    "    b_conv6 = bias_variable([512], \"b_conv6\")\n",
    "\n",
    "    h_conv6 = tf.nn.relu(conv2d(h_conv5, W_conv6) + b_conv6)\n",
    "    \n",
    "    print(h_conv6.get_shape())\n",
    "    \n",
    "    #Mid Level features\n",
    "    W_midlvl1 = weight_variable([3, 3, 512, 512], \"W_midlvl1\")\n",
    "    b_midlvl1 = bias_variable([512], \"b_midlvl1\")\n",
    "\n",
    "    h_midlvl1 = tf.nn.relu(conv2d(h_conv6, W_midlvl1) + b_midlvl1)\n",
    "    #h_pool_midlvl1 = max_pool_2x2(h_midlvl1)\n",
    "\n",
    "    print(h_midlvl1.get_shape())\n",
    "    \n",
    "    W_midlvl2 = weight_variable([3, 3, 512, 256], \"W_midlvl2\")\n",
    "    b_midlvl2 = bias_variable([256], \"b_midlvl2\")\n",
    "\n",
    "    h_midlvl2 = tf.nn.relu(conv2d(h_midlvl1, W_midlvl2) + b_midlvl2)\n",
    "\n",
    "    print(h_midlvl2.get_shape())\n",
    "\n",
    "    #Colorization Network\n",
    "    \n",
    "    #Upsample\n",
    "    h_conv_t_4 = tf.image.resize_images(h_midlvl2, [64, 64], method=1) #1=nearest neighbour\n",
    "    print(\"rs 1\")\n",
    "    print(h_conv_t_4.get_shape())\n",
    "    \n",
    "    # CNN conv\n",
    "    \n",
    "    W_colorizer_CNN1 = weight_variable([3, 3, 256 , 128], \"W_colorizer_CNN1\")\n",
    "    b_colorizer_CNN1 = bias_variable([128], \"b_colorizer_CNN1\")\n",
    "\n",
    "    h_colorizer_conv1 = tf.nn.relu6(conv2d(h_conv_t_4, W_colorizer_CNN1) + b_colorizer_CNN1)\n",
    "    \n",
    "    print(h_colorizer_conv1.get_shape())\n",
    "    \n",
    "    \n",
    "    #Upsample\n",
    "    h_conv_t_5 = tf.image.resize_images(h_colorizer_conv1, [128, 128], method=1) #1=nearest neighbour\n",
    "    print(\"rs 2\")\n",
    "    print(h_conv_t_5.get_shape())\n",
    "    \n",
    "    \n",
    "    # CNN conv\n",
    "    W_colorizer_CNN2 = weight_variable([3, 3, 128 , 64], \"W_colorizer_CNN2\")\n",
    "    b_colorizer_CNN2 = bias_variable([64], \"b_colorizer_CNN2\")\n",
    "\n",
    "    h_colorizer_conv2 = tf.nn.relu6(conv2d(h_conv_t_5, W_colorizer_CNN2) + b_colorizer_CNN2)\n",
    "    \n",
    "    print(h_colorizer_conv2.get_shape())\n",
    "    \n",
    "    \n",
    "    #Upsample\n",
    "    h_conv_t_6 = tf.image.resize_images(h_colorizer_conv2, [256, 256], method=1) #1=nearest neighbour\n",
    "    print(\"rs 3\")\n",
    "    print(h_conv_t_6.get_shape())\n",
    "    \n",
    "    # CNN conv\n",
    "    W_colorizer_CNN3 = weight_variable([3, 3, 64 , 3], \"W_colorizer_CNN3\")\n",
    "    b_colorizer_CNN3 = bias_variable([3], \"b_colorizer_CNN3\")\n",
    "\n",
    "    h_colorizer_conv3 = tf.nn.relu6(conv2d(h_conv_t_6, W_colorizer_CNN3) + b_colorizer_CNN3)\n",
    "    print(h_colorizer_conv3.get_shape())\n",
    "    \n",
    "    \n",
    "    W_last = weight_variable([3, 3, 3, 3], \"W_last\")\n",
    "    b_last = bias_variable([3], \"b_last\")\n",
    "    last_cnn = tf.nn.sigmoid(conv2d(h_colorizer_conv3, W_last) + b_last, name=\"color_image\")\n",
    "    \n",
    "    \n",
    "    print(last_cnn.get_shape())\n",
    "\n",
    "    #to_save = [W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3, W_transpose_conv1, b_transpose_conv1, W_transpose_conv2, b_transpose_conv2, W_transpose_conv3, b_transpose_conv3]    \n",
    "    \n",
    "    _lambda = 0.005;\n",
    "  \n",
    "    \n",
    "    l1_regularizer = tf.contrib.layers.l1_regularizer(scale=_lambda, scope=None)\n",
    "   \n",
    "    weights = [W_conv1, W_conv2, W_conv3, W_conv4, W_conv5, W_conv6, W_midlvl1, W_midlvl2,\n",
    "                    W_colorizer_CNN1, W_colorizer_CNN2,\n",
    "                        W_colorizer_CNN3, W_last]\n",
    "    \n",
    "    regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, weights)\n",
    "    \n",
    "    #Loss computation\n",
    "    gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(last_cnn - y)) + regularization_penalty\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(gen_loss_mse)\n",
    "    \n",
    "    #pred image\n",
    "    tf.add_to_collection('optimizer', optimizer)  \n",
    "    tf.add_to_collection('loss', gen_loss_mse) \n",
    "    tf.add_to_collection('color_image', last_cnn)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Training\n",
    "    for itr in range(hm_epochs):\n",
    "        #image, color_images = get_next_batch(train_features, train_labels)\n",
    "        image, color_images = get_next_batch_from_disk_RGB_Nocrop(images_list=images_list, batch_size=batch_size)\n",
    "        #print(image.shape)\n",
    "        feed_dict = {x: image, y: color_images}\n",
    "        sess.run(optimizer, feed_dict=feed_dict)\n",
    "        \n",
    "        if itr % 100 == 0:\n",
    "            mse = sess.run(gen_loss_mse, feed_dict=feed_dict)\n",
    "            sess.run(optimizer, feed_dict=feed_dict)\n",
    "            print(\"Step: %d, MSE: %g\" % (itr, mse))\n",
    "     \n",
    "    saver.save(sess, model_path)\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 64)\n",
      "(1, 128, 128, 128)\n",
      "(1, 64, 64, 128)\n",
      "(1, 64, 64, 256)\n",
      "(1, 32, 32, 256)\n",
      "(1, 32, 32, 512)\n",
      "(1, 32, 32, 512)\n",
      "(1, 32, 32, 256)\n",
      "rs 1\n",
      "(1, 64, 64, 256)\n",
      "(1, 64, 64, 128)\n",
      "rs 2\n",
      "(1, 128, 128, 128)\n",
      "(1, 128, 128, 64)\n",
      "rs 3\n",
      "(1, 256, 256, 64)\n",
      "(1, 256, 256, 3)\n",
      "(1, 256, 256, 3)\n",
      "Step: 0, MSE: 8138.69\n",
      "Step: 100, MSE: 6891.7\n",
      "Step: 200, MSE: 6383.14\n",
      "Step: 300, MSE: 6104.76\n",
      "Step: 400, MSE: 5930.78\n",
      "Step: 500, MSE: 5818.62\n",
      "Step: 600, MSE: 5740.91\n",
      "Step: 700, MSE: 5680.94\n",
      "Step: 800, MSE: 5633.58\n",
      "Step: 900, MSE: 5586.99\n"
     ]
    }
   ],
   "source": [
    "#Global constants\n",
    "seed = 56\n",
    "\n",
    "#cycles of feed forward + backprop on all K-folded samples\n",
    "hm_epochs = 1000\n",
    "\n",
    "model_path = \"./test5/model.ckpt\"\n",
    "save_dir = './test5/'\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, 256, 256, 1], name = 'x')\n",
    "y = tf.placeholder(tf.float32, shape=[batch_size, 256, 256, 3], name='y')\n",
    "#dropout_prob = tf.placeholder('float', (), name = 'dropout_prob')\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "train_neural_network_colorization_sig2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def train_neural_network_colorization_sig(x):\n",
    "    \n",
    "    strides1 = [1, 1, 1, 1]\n",
    "    strides2 = [1, 2, 2, 1]\n",
    "    \n",
    "    # first convolutional layer\n",
    "    W_conv1 = weight_variable([3, 3, 1, 64], \"W_conv1\")\n",
    "    b_conv1 = bias_variable([64], \"b_conv1\")\n",
    "\n",
    "    h_conv1 = tf.nn.relu6(conv2d(x, W_conv1, strides2) + b_conv1)\n",
    "    \n",
    "    print(h_conv1.get_shape())\n",
    "    \n",
    "    #Second CNN layer\n",
    "    W_conv2 = weight_variable([3, 3, 64, 128], \"W_conv2\")\n",
    "    b_conv2 = bias_variable([128], \"b_conv2\")\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "    \n",
    "    print(h_conv2.get_shape())\n",
    "    \n",
    "    #Third CNN Layer\n",
    "    W_conv3 = weight_variable([3, 3, 128, 128], \"W_conv3\")\n",
    "    b_conv3 = bias_variable([128], \"b_conv3\")\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, strides2) + b_conv3)\n",
    "    \n",
    "    print(h_conv3.get_shape())\n",
    "    \n",
    "    #Fourth CNN Layer\n",
    "    W_conv4 = weight_variable([3, 3, 128, 256], \"W_conv4\")\n",
    "    b_conv4 = bias_variable([256], \"b_conv4\")\n",
    "\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4 ) + b_conv4)\n",
    "    \n",
    "    print(h_conv4.get_shape())\n",
    "    \n",
    "    #Fifth CNN Layer\n",
    "    W_conv5 = weight_variable([3, 3, 256, 256], \"W_conv5\")\n",
    "    b_conv5 = bias_variable([256], \"b_conv5\")\n",
    "\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, strides2) + b_conv5)\n",
    "    \n",
    "    print(h_conv5.get_shape())\n",
    "    \n",
    "    #Sixth CNN Layer\n",
    "    W_conv6 = weight_variable([3, 3, 256, 512], \"W_conv6\")\n",
    "    b_conv6 = bias_variable([512], \"b_conv6\")\n",
    "\n",
    "    h_conv6 = tf.nn.relu(conv2d(h_conv5, W_conv6) + b_conv6)\n",
    "    \n",
    "    print(h_conv6.get_shape())\n",
    "    \n",
    "    #Mid Level features\n",
    "    W_midlvl1 = weight_variable([3, 3, 512, 512], \"W_midlvl1\")\n",
    "    b_midlvl1 = bias_variable([512], \"b_midlvl1\")\n",
    "\n",
    "    h_midlvl1 = tf.nn.relu(conv2d(h_conv6, W_midlvl1) + b_midlvl1)\n",
    "    #h_pool_midlvl1 = max_pool_2x2(h_midlvl1)\n",
    "\n",
    "    print(h_midlvl1.get_shape())\n",
    "    \n",
    "    W_midlvl2 = weight_variable([3, 3, 512, 256], \"W_midlvl2\")\n",
    "    b_midlvl2 = bias_variable([256], \"b_midlvl2\")\n",
    "\n",
    "    h_midlvl2 = tf.nn.relu(conv2d(h_midlvl1, W_midlvl2) + b_midlvl2)\n",
    "\n",
    "    print(h_midlvl2.get_shape())\n",
    "\n",
    "    #Colorization Network\n",
    "    \n",
    "    #Transposed CNN Layer 1\n",
    "    W_transpose_conv1 = weight_variable([3, 3, 128, 256], \"W_transpose_conv1\")\n",
    "    b_transpose_conv1 = bias_variable([128], \"b_transpose_conv1\")\n",
    "\n",
    "    h_conv_t_4 = conv2d_transpose_strided(h_midlvl2, W_transpose_conv1) + b_transpose_conv1\n",
    "    \n",
    "    print(h_conv_t_4.get_shape())\n",
    "    \n",
    "    # CNN conv\n",
    "    \n",
    "    W_colorizer_CNN1 = weight_variable([1, 1, 128 , 128], \"W_colorizer_CNN1\")\n",
    "    b_colorizer_CNN1 = bias_variable([128], \"b_colorizer_CNN1\")\n",
    "\n",
    "    h_colorizer_conv1 = tf.nn.relu6(conv2d(h_conv_t_4, W_colorizer_CNN1) + b_colorizer_CNN1)\n",
    "    \n",
    "    print(h_colorizer_conv1.get_shape())\n",
    "\n",
    "    #Transposed CNN Layer 2\n",
    "    W_transpose_conv2 = weight_variable([3, 3, 64, 128], \"W_transpose_conv2\")\n",
    "    b_transpose_conv2 = bias_variable([64], \"b_transpose_conv2\")\n",
    "\n",
    "    h_conv_t_5 = conv2d_transpose_strided(h_colorizer_conv1, W_transpose_conv2) + b_transpose_conv2\n",
    "    \n",
    "    print(h_conv_t_5.get_shape())\n",
    "    \n",
    "    \n",
    "    # CNN conv\n",
    "    \n",
    "    W_colorizer_CNN2 = weight_variable([1, 1, 64 , 64], \"W_colorizer_CNN2\")\n",
    "    b_colorizer_CNN2 = bias_variable([64], \"b_colorizer_CNN2\")\n",
    "\n",
    "    h_colorizer_conv2 = tf.nn.relu6(conv2d(h_conv_t_5, W_colorizer_CNN2) + b_colorizer_CNN2)\n",
    "    \n",
    "    print(h_colorizer_conv2.get_shape())\n",
    "    \n",
    "      \n",
    "    #Transposed CNN Layer 3\n",
    "    W_transpose_conv3 = weight_variable([3, 3, 32, 64], \"W_transpose_conv3\")\n",
    "    b_transpose_conv3 = bias_variable([32], \"b_transpose_conv3\")\n",
    "\n",
    "    h_conv_t_6 = tf.add(conv2d_transpose_strided(h_colorizer_conv2, W_transpose_conv3), b_transpose_conv3)\n",
    "    \n",
    "    \n",
    "    # CNN conv\n",
    "    W_colorizer_CNN3 = weight_variable([1, 1, 32, 3], \"W_colorizer_CNN3\")\n",
    "    b_colorizer_CNN3 = bias_variable([3], \"b_colorizer_CNN3\")\n",
    "\n",
    "    h_colorizer_conv3 = tf.nn.relu6(conv2d(h_conv_t_6, W_colorizer_CNN3) + b_colorizer_CNN3)\n",
    "    \n",
    "    print(h_colorizer_conv3.get_shape())\n",
    "    \n",
    "    \n",
    "    W_last = weight_variable([1, 1, 3, 3], \"W_last\")\n",
    "    b_last = bias_variable([3], \"b_last\")\n",
    "    last_cnn = tf.nn.sigmoid(conv2d(h_colorizer_conv3, W_last) + b_last, name=\"color_image\")\n",
    "    \n",
    "    \n",
    "    print(last_cnn.get_shape())\n",
    "\n",
    "    #to_save = [W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3, W_transpose_conv1, b_transpose_conv1, W_transpose_conv2, b_transpose_conv2, W_transpose_conv3, b_transpose_conv3]    \n",
    "    \n",
    "    _lambda = 0.005;\n",
    "  \n",
    "    \n",
    "    l1_regularizer = tf.contrib.layers.l1_regularizer(scale=_lambda, scope=None)\n",
    "   \n",
    "    weights = [W_conv1, W_conv2, W_conv3, W_conv4, W_conv5, W_conv6, W_midlvl1, W_midlvl2,\n",
    "                    W_transpose_conv1, W_colorizer_CNN1, W_transpose_conv2, W_colorizer_CNN2, W_transpose_conv3,\n",
    "                        W_colorizer_CNN3, W_last]\n",
    "    \n",
    "    regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, weights)\n",
    "    \n",
    "    #Loss computation\n",
    "    gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(last_cnn - y)) + regularization_penalty\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(gen_loss_mse)\n",
    "    \n",
    "    #pred image\n",
    "    tf.add_to_collection('optimizer', optimizer)  \n",
    "    tf.add_to_collection('loss', gen_loss_mse) \n",
    "    tf.add_to_collection('color_image', last_cnn)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #Training\n",
    "    for itr in range(hm_epochs):\n",
    "        #image, color_images = get_next_batch(train_features, train_labels)\n",
    "        image, color_images = get_next_batch_from_disk_RGB_Nocrop(images_list=images_list, batch_size=batch_size)\n",
    "        #print(image.shape)\n",
    "        feed_dict = {x: image, y: color_images}\n",
    "        sess.run(optimizer, feed_dict=feed_dict)\n",
    "        \n",
    "        if itr % 100 == 0:\n",
    "            mse = sess.run(gen_loss_mse, feed_dict=feed_dict)\n",
    "            sess.run(optimizer, feed_dict=feed_dict)\n",
    "            print(\"Step: %d, MSE: %g\" % (itr, mse))\n",
    "     \n",
    "    saver.save(sess, model_path)\n",
    "    \n",
    "    sess.close()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
